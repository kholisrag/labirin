---
# Talos Kubernetes Cluster Configuration
# ========================================

# Cluster Basic Configuration
cluster_name: "main-talos-k8s-cluster"

# Worker Node Discovery Configuration
# Query worker nodes dynamically based on PVE tags
use_dynamic_worker_discovery: true
worker_node_tag: "main-talos-worker"

# Feature Flags
# Encryption for generated Talos configs
auto_encrypt: true

# Remote manifests to download
remote_manifests:
  - name: "kubelet-serving-cert-approver-v0.10.0-ha"
    url: "https://raw.githubusercontent.com/alex1989hu/kubelet-serving-cert-approver/refs/tags/v0.10.0/deploy/ha-install.yaml"
    destination: "talos-init/kubelet-serving-cert-approver-v0.10.0-ha.yaml"
  - name: "kubelet-serving-cert-approver-v0.10.0"
    url: "https://raw.githubusercontent.com/alex1989hu/kubelet-serving-cert-approver/refs/tags/v0.10.0/deploy/standalone-install.yaml"
    destination: "talos-init/kubelet-serving-cert-approver-v0.10.0.yaml"
  - name: "metrics-server-v0.8.0-ha"
    url: "https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.8.0/high-availability-1.21+.yaml"
    destination: "talos-init/metrics-server-v0.8.0-ha.yaml"
  - name: "metrics-server-v0.8.0"
    url: "https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.8.0/components.yaml"
    destination: "talos-init/metrics-server-v0.8.0.yaml"
  - name: "proxmox-cloud-controller-manager"
    url: "https://raw.githubusercontent.com/sergelogvinov/proxmox-cloud-controller-manager/refs/tags/v0.12.2/docs/deploy/cloud-controller-manager-talos.yml"
    destination: "talos-init/proxmox-cloud-controller-manager-v0.12.2.yaml"
  - name: "proxmox-csi-plugin"
    url: "https://raw.githubusercontent.com/sergelogvinov/proxmox-csi-plugin/refs/tags/v0.16.0/docs/deploy/proxmox-csi-plugin-talos.yml"
    destination: "talos-init/proxmox-csi-plugin-v0.16.0.yaml"

# Helm charts to template
helm_charts:
  - name: "cilium-cni-talos-v1.18.4"
    repo_name: "cilium"
    release_name: "cilium"
    chart: "cilium/cilium"
    version: "1.18.4"
    namespace: "kube-system"
    repo_url: "https://helm.cilium.io/"
    destination: "talos-init/talos-cni-cilium-v1.18.4.yaml"
    values: |
      ipam:
        mode: kubernetes
      kubeProxyReplacement: true
      socketLB:
        hostNamespaceOnly: true
      cni:
        exclusive: false
      k8sServiceHost: "{{ cluster_endpoint }}"
      k8sServicePort: 6443
      securityContext:
        capabilities:
          ciliumAgent:
            - CHOWN
            - KILL
            - NET_ADMIN
            - NET_RAW
            - IPC_LOCK
            - SYS_ADMIN
            - SYS_RESOURCE
            - DAC_OVERRIDE
            - FOWNER
            - SETGID
            - SETUID
          cleanCiliumState:
            - NET_ADMIN
            - SYS_ADMIN
            - SYS_RESOURCE
      cgroup:
        autoMount:
          enabled: false
        hostRoot: /sys/fs/cgroup
      hubble:
        ui:
          enabled: true
          rollOutPods: true
        relay:
          enabled: true
          rollOutPods: true
      bpf:
        masquerade: true
      endpointRoutes:
        enabled: true
      localRedirectPolicies:
        enabled: true
      operator:
        rollOutPods: true
        tolerations:
          - key: "node-role.kubernetes.io/control-plane"
            operator: Exists
          - key: "node.kubernetes.io/not-ready"
            operator: Exists
          - key: "node.cloudprovider.kubernetes.io/uninitialized"
            operator: Exists
      envoy:
        rollOutPods: true
      rollOutCiliumPods: true
      bgpControlPlane:
        enabled: true
    custom_manifests: []

  - name: "coredns-custom-talos-opnsense-homelab-v1.13.1"
    repo_name: "coredns"
    release_name: "coredns"
    chart: "coredns/coredns"
    version: "1.45.0"
    namespace: "kube-system"
    repo_url: "https://coredns.github.io/helm"
    destination: "talos-init/coredns-custom-talos-opnsense-homelab-v1.13.1.yaml"
    values: |
      image:
        repository: coredns/coredns
      replicaCount: 3
      resources:
        limits:
          cpu: 200m
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      rollingUpdate:
        maxUnavailable: 1
        maxSurge: 0
      prometheus:
        service:
          enabled: true
          annotations:
            prometheus.io/scrape: "true"
            prometheus.io/port: "9153"
      serviceAccount:
        create: true
        name: coredns
      rbac:
        create: true
      isClusterService: true
      service:
        name: kube-dns
        clusterIP: "10.16.0.10"
        annotations:
          prometheus.io/scrape: "true"
          prometheus.io/port: "9153"
      priorityClassName: "system-cluster-critical"
      podSecurityContext: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
            - NET_BIND_SERVICE
          drop:
            - ALL
        readOnlyRootFilesystem: true
      nodeSelector:
        kubernetes.io/os: linux
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: k8s-app
                      operator: In
                      values:
                        - kube-dns
                topologyKey: kubernetes.io/hostname
      tolerations:
        - key: "node-role.kubernetes.io/control-plane"
          operator: Exists
          effect: NoSchedule
        - key: "node.cloudprovider.kubernetes.io/uninitialized"
          operator: Exists
          effect: NoSchedule
      servers:
        - zones:
            - zone: .
          port: 53
          plugins:
            - name: errors
            - name: health
              configBlock: |-
                lameduck 5s
            - name: ready
            - name: log
              parameters: .
              configBlock: |-
                class error
            - name: prometheus
              parameters: :9153
            - name: kubernetes
              parameters: cluster.local in-addr.arpa ip6.arpa
              configBlock: |-
                pods insecure
                fallthrough in-addr.arpa ip6.arpa
                ttl 30
            - name: forward
              parameters: . 10.10.1.1 /etc/resolv.conf
              configBlock: |-
                max_concurrent 1000
                policy sequential
                health_check 5s
            - name: cache
              parameters: 30
              configBlock: |-
                disable success cluster.local
                disable denial cluster.local
            - name: loop
            - name: reload
            - name: loadbalance
      k8sAppLabelOverride: "kube-dns"
      livenessProbe:
        enabled: true
        initialDelaySeconds: 60
        periodSeconds: 10
        timeoutSeconds: 5
        failureThreshold: 5
        successThreshold: 1
      readinessProbe:
        enabled: true
        initialDelaySeconds: 0
        periodSeconds: 10
        timeoutSeconds: 1
        failureThreshold: 3
        successThreshold: 1
      env:
        - name: GOMEMLIMIT
          value: "161MiB"
    custom_manifests: []

  - name: "talos-cloud-controller-manager-proxmox-v0.5.2"
    oci: true
    release_name: "talos-cloud-controller-manager"
    chart: "oci://ghcr.io/siderolabs/charts/talos-cloud-controller-manager"
    version: "0.5.2"
    namespace: "kube-system"
    destination: "talos-init/talos-cloud-controller-manager-proxmox-v0.5.2.yaml"
    values: |
      enabledControllers:
        - cloud-node
        - node-csr-approval
        # - cloud-node-lifecycle is handled by proxmox-ccm
      # Ref: https://github.com/siderolabs/talos-cloud-controller-manager/blob/main/docs/config.md
      transformations:
        # Transformation for all talos master nodes in proxmox
        - name: proxmox-main-talos-master-nodes
          nodeSelector:
            - matchExpressions:
                # Match Talos nodes running on Proxmox platform
                - key: platform
                  operator: In
                  values:
                    - nocloud
                # Match nodes with talos hostname pattern
                - key: hostname
                  operator: Regexp
                  values:
                    - ^main-talos-master-.+$
          # Add worker role label
          labels:
            node-role.kubernetes.io/control-plane: ""
          # Set platform metadata
          platformMetadata:
            # set region to match proxmox cluster name
            Region: "petruk-pve"
            # set zone to match proxmox node name
            Zone: "petruk-pve0"
            # Set providerID for Proxmox CSI to identify VMs
            ProviderID: "proxmox://petruk-pve/{{ '{{' }} .UUID {{ '}}' }}"
          features:
            publicIPDiscovery: false
        # Transformation for all talos non-master nodes in proxmox
        - name: proxmox-main-talos-worker-nodes
          nodeSelector:
            - matchExpressions:
                # Match Talos nodes running on Proxmox platform
                - key: platform
                  operator: In
                  values:
                    - nocloud
                # Match nodes with talos hostname pattern
                - key: hostname
                  operator: Regexp
                  values:
                    - ^talos-.+$
          # Add worker role label
          labels:
            node-role.kubernetes.io/worker: ""
          # Set platform metadata
          platformMetadata:
            # set region to match proxmox cluster name
            Region: "petruk-pve"
            # set zone to match proxmox node name
            Zone: "petruk-pve0"
            # Set providerID for Proxmox CSI to identify VMs
            ProviderID: "proxmox://petruk-pve/{{ '{{' }} .UUID {{ '}}' }}"
          features:
            publicIPDiscovery: false
      tolerations:
        - effect: NoSchedule
          operator: Exists

# Additional manifests to include
local_manifests:
  - name: "proxmox-ccm-secrets"
    source: "{{ playbook_dir }}/vars/manifests/proxmox-ccm-secrets.enc.yaml"
    destination: "talos-init/proxmox/proxmox-cloud-controller-manager-secrets.yaml"
    encrypt: true
  - name: "proxmox-csi"
    source: "{{ playbook_dir }}/vars/manifests/proxmox-csi.yaml"
    destination: "talos-init/proxmox/proxmox-csi.yaml"
  - name: "proxmox-csi-secrets"
    source: "{{ playbook_dir }}/vars/manifests/proxmox-csi-secrets.enc.yaml"
    destination: "talos-init/proxmox/proxmox-csi-secrets.yaml"
    encrypt: true
