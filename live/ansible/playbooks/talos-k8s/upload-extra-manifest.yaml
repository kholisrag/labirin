---
- name: Upload Extra K8s Manifests to Internal Static CDN
  hosts: localhost
  gather_facts: true
  vars_files:
    - vars/vault.yaml

  vars:
    work_dir: "{{ playbook_dir }}/extra-manifests/k8s-manifests-{{ ansible_facts['date_time']['epoch'] }}"

    # Remote manifests to download
    remote_manifests:
      - name: "kubelet-serving-cert-approver-v0.10.0-ha"
        url: "https://raw.githubusercontent.com/alex1989hu/kubelet-serving-cert-approver/refs/tags/v0.10.0/deploy/ha-install.yaml"
        destination: "talos-init/kubelet-serving-cert-approver-v0.10.0-ha.yaml"
      - name: "kubelet-serving-cert-approver-v0.10.0"
        url: "https://raw.githubusercontent.com/alex1989hu/kubelet-serving-cert-approver/refs/tags/v0.10.0/deploy/standalone-install.yaml"
        destination: "talos-init/kubelet-serving-cert-approver-v0.10.0.yaml"
      - name: "metrics-server-v0.8.0-ha"
        url: "https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.8.0/high-availability-1.21+.yaml"
        destination: "talos-init/metrics-server-v0.8.0-ha.yaml"
      - name: "metrics-server-v0.8.0"
        url: "https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.8.0/components.yaml"
        destination: "talos-init/metrics-server-v0.8.0.yaml"
      - name: "proxmox-cloud-controller-manager"
        url: "https://raw.githubusercontent.com/sergelogvinov/proxmox-cloud-controller-manager/refs/tags/v0.12.2/docs/deploy/cloud-controller-manager-talos.yml"
        destination: "talos-init/proxmox-cloud-controller-manager-v0.12.2.yaml"
      - name: "proxmox-csi-plugin"
        url: "https://raw.githubusercontent.com/sergelogvinov/proxmox-csi-plugin/refs/tags/v0.16.0/docs/deploy/proxmox-csi-plugin-talos.yml"
        destination: "talos-init/proxmox-csi-plugin-v0.16.0.yaml"

    # Helm charts to template
    helm_charts:
      - name: "cilium-cni-talos-v1.18.4"
        release_name: "cilium"
        chart: "cilium/cilium"
        version: "1.18.4"
        namespace: "kube-system"
        repo_url: "https://helm.cilium.io/"
        destination: "talos-init/talos-cni-cilium-v1.18.4.yaml"
        values: |
          ipam:
            mode: kubernetes
          kubeProxyReplacement: true
          k8sServiceHost: "{{ cluster_endpoint }}"
          k8sServicePort: 6443
          securityContext:
            capabilities:
              ciliumAgent:
                - CHOWN
                - KILL
                - NET_ADMIN
                - NET_RAW
                - IPC_LOCK
                - SYS_ADMIN
                - SYS_RESOURCE
                - DAC_OVERRIDE
                - FOWNER
                - SETGID
                - SETUID
              cleanCiliumState:
                - NET_ADMIN
                - SYS_ADMIN
                - SYS_RESOURCE
          cgroup:
            autoMount:
              enabled: false
            hostRoot: /sys/fs/cgroup
          hubble:
            ui:
              enabled: true
              rollOutPods: true
            relay:
              enabled: true
              rollOutPods: true
          bpf:
            masquerade: true
          endpointRoutes:
            enabled: true
          localRedirectPolicies:
            enabled: true
          operator:
            rollOutPods: true
            tolerations:
              - key: "node-role.kubernetes.io/control-plane"
                operator: Exists
              - key: "node.kubernetes.io/not-ready"
                operator: Exists
              - key: "node.cloudprovider.kubernetes.io/uninitialized"
                operator: Exists
          envoy:
            rollOutPods: true
          rollOutCiliumPods: true
        custom_manifests: []

      - name: "coredns-custom-talos-opnsense-homelab-v1.13.1"
        release_name: "coredns"
        chart: "coredns/coredns"
        version: "1.45.0"
        namespace: "kube-system"
        repo_url: "https://coredns.github.io/helm"
        destination: "talos-init/coredns-custom-talos-opnsense-homelab-v1.13.1.yaml"
        values: |
          image:
            repository: coredns/coredns
          replicaCount: 3
          resources:
            limits:
              cpu: 200m
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          rollingUpdate:
            maxUnavailable: 1
            maxSurge: 0
          prometheus:
            service:
              enabled: true
              annotations:
                prometheus.io/scrape: "true"
                prometheus.io/port: "9153"
          serviceAccount:
            create: true
            name: coredns
          rbac:
            create: true
          isClusterService: true
          service:
            name: kube-dns
            annotations:
              prometheus.io/scrape: "true"
              prometheus.io/port: "9153"
          priorityClassName: "system-cluster-critical"
          podSecurityContext: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
                - NET_BIND_SERVICE
              drop:
                - ALL
            readOnlyRootFilesystem: true
          nodeSelector:
            kubernetes.io/os: linux
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
                - weight: 100
                  podAffinityTerm:
                    labelSelector:
                      matchExpressions:
                        - key: k8s-app
                          operator: In
                          values:
                            - kube-dns
                    topologyKey: kubernetes.io/hostname
          tolerations:
            - key: "node-role.kubernetes.io/control-plane"
              operator: Exists
              effect: NoSchedule
            - key: "node.cloudprovider.kubernetes.io/uninitialized"
              operator: Exists
              effect: NoSchedule
          servers:
            - zones:
                - zone: .
              port: 53
              plugins:
                - name: errors
                - name: health
                  configBlock: |-
                    lameduck 5s
                - name: ready
                - name: log
                  parameters: .
                  configBlock: |-
                    class error
                - name: prometheus
                  parameters: :9153
                - name: kubernetes
                  parameters: cluster.local in-addr.arpa ip6.arpa
                  configBlock: |-
                    pods insecure
                    fallthrough in-addr.arpa ip6.arpa
                    ttl 30
                - name: forward
                  parameters: . 10.10.1.1 /etc/resolv.conf
                  configBlock: |-
                    max_concurrent 1000
                    policy sequential
                    health_check 5s
                - name: cache
                  parameters: 30
                  configBlock: |-
                    disable success cluster.local
                    disable denial cluster.local
                - name: loop
                - name: reload
                - name: loadbalance

          livenessProbe:
            enabled: true
            initialDelaySeconds: 60
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 5
            successThreshold: 1
          readinessProbe:
            enabled: true
            initialDelaySeconds: 0
            periodSeconds: 10
            timeoutSeconds: 1
            failureThreshold: 3
            successThreshold: 1
          env:
            - name: GOMEMLIMIT
              value: "161MiB"
        custom_manifests: []

    # Additional manifests to include
    local_manifests:
      - name: "proxmox-ccm-secrets"
        source: "{{ playbook_dir }}/vars/manifests/proxmox-ccm-secrets.enc.yaml"
        destination: "talos-init/proxmox/proxmox-cloud-controller-manager-secrets.yaml"
        encrypt: true
      - name: "proxmox-csi"
        source: "{{ playbook_dir }}/vars/manifests/proxmox-csi.yaml"
        destination: "talos-init/proxmox/proxmox-csi.yaml"
      - name: "proxmox-csi-secrets"
        source: "{{ playbook_dir }}/vars/manifests/proxmox-csi-secrets.enc.yaml"
        destination: "talos-init/proxmox/proxmox-csi-secrets.yaml"
        encrypt: true

  tasks:
    - name: Create temporary working directory
      ansible.builtin.file:
        path: "{{ work_dir }}"
        state: directory
        mode: "0755"

    - name: Download remote manifests
      ansible.builtin.get_url:
        url: "{{ item.url }}"
        dest: "{{ work_dir }}/remote-{{ item.name }}.yaml"
        mode: "0644"
      loop: "{{ remote_manifests }}"
      loop_control:
        loop_var: item
        label: "{{ item.name }}"

    - name: Copy local manifests to work directory (unencrypted)
      ansible.builtin.copy:
        src: "{{ item.source }}"
        dest: "{{ work_dir }}/local-{{ item.name }}.yaml"
        mode: "0644"
      loop: "{{ local_manifests }}"
      loop_control:
        loop_var: item
        label: "{{ item.name }}"
      when:
        - local_manifests is defined and local_manifests | length > 0
        - not (item.encrypt | default(false))

    - name: Decrypt encrypted local manifests
      ansible.builtin.shell: |
        sops -d "{{ item.source }}" > "{{ work_dir }}/local-{{ item.name }}.yaml"
      loop: "{{ local_manifests }}"
      loop_control:
        loop_var: item
        label: "{{ item.name }}"
      when:
        - local_manifests is defined and local_manifests | length > 0
        - item.encrypt | default(false)
      changed_when: false

    - name: Add Helm repositories
      ansible.builtin.command:
        cmd: helm repo add {{ item.name }} {{ item.repo_url }}
      loop: "{{ helm_charts }}"
      loop_control:
        label: "{{ item.name }}"
      changed_when: false
      failed_when: false

    - name: Update Helm repositories
      ansible.builtin.command:
        cmd: helm repo update
      changed_when: false

    - name: Create Helm values files
      ansible.builtin.copy:
        dest: "{{ work_dir }}/{{ item.name }}-values.yaml"
        content: "{{ item['values'] }}"
        mode: "0644"
      loop: "{{ helm_charts }}"
      loop_control:
        label: "{{ item.name }}"

    - name: Generate Helm chart manifests
      ansible.builtin.command:
        cmd: >
          helm template {{ item.release_name }} {{ item.chart }}
          --version {{ item.version }}
          --namespace {{ item.namespace }}
          --values {{ work_dir }}/{{ item.name }}-values.yaml
      loop: "{{ helm_charts }}"
      loop_control:
        label: "{{ item.name }}"
      register: helm_manifests
      changed_when: false

    - name: Create custom manifests for each helm chart
      ansible.builtin.copy:
        dest: "{{ work_dir }}/{{ item.0.name }}-custom.yaml"
        content: "{{ item.1.content }}"
        mode: "0644"
      loop: "{{ helm_charts | subelements('custom_manifests', skip_missing=True) }}"
      loop_control:
        label: "{{ item.0.name }} - {{ item.1.name }}"

    - name: Save Helm generated manifests to temp files
      ansible.builtin.copy:
        dest: "{{ work_dir }}/{{ item.item.name }}-helm-output.yaml"
        content: "{{ item.stdout }}"
        mode: "0644"
      loop: "{{ helm_manifests.results }}"
      loop_control:
        label: "{{ item.item.name }}"

    - name: Combine custom manifests and helm output for each chart
      ansible.builtin.shell: |
        set -o pipefail
        OUTPUT_FILE="{{ work_dir }}/helm-{{ item.name }}.yaml"
        HELM_OUTPUT="{{ work_dir }}/{{ item.name }}-helm-output.yaml"
        CUSTOM_MANIFEST="{{ work_dir }}/{{ item.name }}-custom.yaml"

        # Start with empty file
        > "$OUTPUT_FILE"

        # Add custom manifest if it exists
        if [ -f "$CUSTOM_MANIFEST" ]; then
          cat "$CUSTOM_MANIFEST" >> "$OUTPUT_FILE"
          echo "" >> "$OUTPUT_FILE"
        fi

        # Add helm generated manifest
        cat "$HELM_OUTPUT" >> "$OUTPUT_FILE"
      args:
        executable: /bin/bash
      loop: "{{ helm_charts }}"
      loop_control:
        loop_var: item
        label: "{{ item.name }}"
      changed_when: false

    - name: Build manifest to destination mapping
      ansible.builtin.set_fact:
        manifest_map: |
          {% set result = [] %}
          {% for item in remote_manifests %}
          {{ result.append({'local': work_dir ~ '/remote-' ~ item.name ~ '.yaml', 'remote': item.destination}) or '' }}
          {% endfor %}
          {% for item in (local_manifests | default([])) %}
          {{ result.append({'local': work_dir ~ '/local-' ~ item.name ~ '.yaml', 'remote': item.destination}) or '' }}
          {% endfor %}
          {% for item in helm_charts %}
          {{ result.append({'local': work_dir ~ '/helm-' ~ item.name ~ '.yaml', 'remote': item.destination}) or '' }}
          {% endfor %}
          {{ result }}

    - name: Parse manifest mapping
      ansible.builtin.set_fact:
        manifest_map: "{{ manifest_map | from_yaml }}"

    - name: Display files to be uploaded
      ansible.builtin.debug:
        msg: "Uploading {{ manifest_map | length }} manifest files to {{ static_cdn_internal_pve_vm_name }}"

    - name: Ensure destination directories exist on remote host
      ansible.builtin.file:
        path: "{{ static_cdn_internal_dir_path }}/{{ item.remote | dirname }}"
        state: directory
        mode: "0775"
        owner: "{{ static_cdn_internal_user }}"
        group: "{{ static_cdn_internal_user }}"
      delegate_to: "{{ static_cdn_internal_pve_vm_name }}"
      become: true
      loop: "{{ manifest_map }}"
      loop_control:
        label: "{{ item.remote | dirname }}"

    - name: Upload manifests to remote host using destination paths
      ansible.builtin.copy:
        src: "{{ item.local }}"
        dest: "{{ static_cdn_internal_dir_path }}/{{ item.remote }}"
        mode: "0644"
        owner: "{{ static_cdn_internal_user }}"
        group: "{{ static_cdn_internal_user }}"
      delegate_to: "{{ static_cdn_internal_pve_vm_name }}"
      become: true
      loop: "{{ manifest_map }}"
      loop_control:
        label: "{{ item.remote }}"

    - name: Display upload completion message
      ansible.builtin.debug:
        msg:
          - "âœ… Manifests uploaded successfully to {{ static_cdn_internal_pve_vm_name }}:{{ static_cdn_internal_dir_path }}"
          - "ðŸ“‹ Individual manifests ({{ manifest_map | length }} files):"
          - "{% for item in manifest_map %}  - https://{{ static_cdn_internal_domain }}/{{ item.remote }}{% endfor %}"

    - name: Cleanup temporary directory (optional)
      ansible.builtin.file:
        path: "{{ work_dir }}"
        state: absent
      when: cleanup_temp | default(true) | bool
